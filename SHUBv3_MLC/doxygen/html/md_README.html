<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Machine_Learning_Core_STM32WL55/SHUBv3_MLC: README</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Machine_Learning_Core_STM32WL55/SHUBv3_MLC
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('md_README.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">README</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><b>Machine Learning Core with STM MEMS</b></p>
<p><b>Sensor LSM6DSOX</b></p>
<p>Harris Koutsourelakis</p>
<p>V1.0</p>
<p>14 Sep 2022</p>
<p><span id="_Toc119493230" class="anchor"></span><b>Abstract</b></p>
<blockquote class="doxtable">
<p>&zwj;This work presents the methodology to develop AI-based applications for Internet-of-Things environments, such as detection of a falling object by using the machine learning core inside the STM Mems Sensor LSM6DSOX and the toolchain Unico, Unicleo and WEKA. </p>
</blockquote>
<h1><a class="anchor" id="autotoc_md23"></a>
Table of Contents</h1>
<p>**Abstract**</p>
<p>1 **Equipment**</p>
<p>1.1 **B-L072Z-LRWAN1**</p>
<p>1.2 **X-NUCLEO-IKS01A3**</p>
<p>1.3 **STEVAL-MKI197V1**</p>
<p>2 **Hardware Synthesis**</p>
<p>2.1 **Connection between B-L072Z-LRWAN1 and X-NUCLEO-IKS01A3**</p>
<p>2.2 **Connection between X-NUCLEO-IKS01A3 and STEVAL-MKI197V1**</p>
<p>2.3 **LSM6DSOX Sensor Initialization**</p>
<p>3 **Firmware and Software**</p>
<p>3.1 **Firmware**</p>
<p>3.2 **Unicleo-GUI**</p>
<p>3.3 **Unico-GUI**</p>
<p>3.4 **Weka**</p>
<p>4 **Implementation**</p>
<p>4.1 **STM32CubeIDE**</p>
<p>4.2 **Unicleo-GUI**</p>
<p>4.3 **Machine Learning Core Example**</p>
<p>4.4 **Unico-GUI**</p>
<p>4.5 **Weka**</p>
<p>4.6 **Video Demonstration**</p>
<p>5 **Falling Detection Algorithm**</p>
<p>5.1 **Creation of Falling Detection Datasets**</p>
<p>5.2 **Project Equipment**</p>
<p>5.3 **Video Demonstration**</p>
<p>5.4 **Possible Real-World Use Scenarios**</p>
<p>6 **Falling Detection Algorithm With NUCLEO-WL55JCx and SHUBv3**</p>
<p>6.1 **Equipment**</p>
<p>6.2 **Decision Tree Generation**</p>
<p>6.2.1 **K-fold Cross-Validation**</p>
<p>6.2.2 **J48 Algorithm (also known as C4.5)**</p>
<p>6.3 **Performance**</p>
<p>6.4 **Video Demonstration**</p>
<p>7 **References**</p>
<h1><a class="anchor" id="autotoc_md24"></a>
<b>Equipment</b></h1>
<p>The equipment used in this project consists of the board <a href="https://www.st.com/en/evaluation-tools/b-l072z-lrwan1.html">B-L072Z-LRWAN1</a>, the [X-NUCLEO-IKS01A3 extender and the <a href="https://www.st.com/en/evaluation-tools/steval-mki197v1.html">STEVAL-MKI197V1</a>. The IKS01A3 is the extension board that provides the DIL24 socket that the <a href="https://www.st.com/en/evaluation-tools/steval-mki197v1.html">MKI197V1</a> (Machine Learning Core LSM6DOX) connects to in order to communicate with the board.](<a href="https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html">https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html</a>)</p>
<h2><a class="anchor" id="autotoc_md25"></a>
<b>B-L072Z-LRWAN1</b></h2>
<p>The <b>B-L072Z-LRWAN1</b>\[1\] board was chosen specifically for this project due to its portability, LoRaWan Connectivity and low battery consumption.</p>
<p><img src="images/1_1.JPG" alt="" style="width:2.42708in;height:2.06944in" class="inline"/>**<a href="https://www.st.com/en/evaluation-tools/b-l072z-lrwan1.html">B-L072Z-LRWAN1</a> <br  />
</p>
<h2><a class="anchor" id="autotoc_md26"></a>
<b>X-NUCLEO-IKS01A3</b></h2>
<p>The <a href="https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html">X-NUCLEO-IKS01A3</a>\[2\] is a is a motion MEMS and environmental sensor evaluation board system. It is compatible with the Arduino UNO R3 connector layout and features the LSM6DSO 3-axis accelerometer + 3-axis gyroscope, the LIS2MDL 3-axis magnetometer, the LIS2DW12 3-axis accelerometer, the HTS221 humidity and temperature sensor, the LPS22HH pressure sensor, and the STTS751 temperature sensor.</p>
<p>The X-NUCLEO-IKS01A3 interfaces with the STM32 microcontroller via the I²C pin, and it is possible to change the default I²C port.</p>
<p><a href="https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html">**X-NUCLEO-IKS01A3 **</a></p>
<p><img src="images/2_2.JPG" alt="A picture containing electronics, circuit Description automatically generated" style="width:2.83158in;height:2.80208in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md27"></a>
<b>STEVAL-MKI197V1</b></h2>
<p>The <a href="https://www.st.com/en/evaluation-tools/steval-mki197v1.html">STEVAL-MKI197V1</a>\[3\] is an adapter board designed to facilitate the evaluation of MEMS devices in the LSM6DSO product family. The board offers an effective solution for fast system prototyping and device evaluation directly within the user’s own application.</p>
<p>STEVAL-MKI197V1</p>
<p><img src="images/3_3.JPG" alt="" style="width:2.65947in;height:1.96875in" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md28"></a>
<b>Hardware Synthesis</b></h1>
<h2><a class="anchor" id="autotoc_md29"></a>
<b>Connection between B-L072Z-LRWAN1 and X-NUCLEO-IKS01A3</b></h2>
<p>First, the <b>X-NUCLEO-IKS01A3</b> needs to be connected to the Arduino R3 pinouts of <b>B-L072Z-LRWAN1</b>. This gives the option to connect the <b>STEVAL-MKI197V1</b> to the DIL24 socket on top of the Nucleo extender.</p>
<p><img src="images/4_4.jpg" alt="" style="width:4.32222in;height:5.90625in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md30"></a>
<b>Connection between X-NUCLEO-IKS01A3 and STEVAL-MKI197V1</b></h2>
<p>Next, the <b>STEVAL-MKI197V1</b> must be connected on the <b>DIL24 Socket</b> of the <b>X-NUCLEO-IKS01A3</b>.</p>
<p><b>IMPORTANT</b>: Make sure the ST Logo on BOTH the extender and the adapter are aligned, otherwise the adapter will overheat and most likely lead to short-circuit.</p>
<p><img src="images/5_5.JPG" alt="" style="width:3.23056in;height:3.84306in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md31"></a>
<b>LSM6DSOX Sensor Initialization</b></h2>
<p>The <b>LSM6DSOX</b> (Machine Learning Core) sensor on the <b>MKI197V1</b> does not communicate out of the box with the <b>IKS01A3</b>. The <b>LSM6DSOX</b> sensor starts in <b>I3C</b>\[4\] mode (also known as SenseWire) because of a level shifter on the <b>IKS01A3</b> that keeps the INT1 of the <b>LSM6DSOX</b> high, this results to <b>I3C</b> initialization by default (as described in the Datasheet).</p>
<p>The only solution that was found was to bypass the INT1 and route the INT2 in its place. That can be done by connecting the A5 pin of the IKS01A3 to GND with a wire and also change the JP6 Jumper from the default 5-6 to 13-14. The change of the Jumper supposedly sets the M_INT2_0 on pin D2, in case a change needs to be made in the schematic.</p>
<p><b>After these changes, the LSM6DSOX sensor will be enabled.</b></p>
<p><img src="images/6_6.JPG" alt="" style="width:5.025in;height:2.97083in" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md32"></a>
<b>Firmware and Software</b></h1>
<h2><a class="anchor" id="autotoc_md33"></a>
<b>Firmware</b></h2>
<p>The Firmware that was used is <a href="https://github.com/STMicroelectronics/X-CUBE-MEMS1">the X-CUBE-MEMS1 Firmware Package</a>\[5\].</p>
<p>The X-CUBE-MEMS1 expansion software package for STM32Cube runs on the STM32 and includes drivers that recognize the sensors and collect temperature, humidity, pressure, and motion data. The expansion is built on STM32Cube software technology to ease portability across different STM32 microcontrollers. The software comes with a sample implementation of the drivers running on the X-NUCLEO-IKS01A2/X-NUCLEO-IKS01A3/X-NUCLEO-IKS02A1 expansion boards connected to a featured STM32 Nucleo development board. The software is also available on GitHub, where the users can signal bugs and propose new ideas through Issues and Pull requests tabs.</p>
<p><b>Note</b>: Inside the repository folder <b>Projects</b>, the only available options are Nucleo-based projects. The ones that were tested though, work just fine with other ST boards, since one of the <b>Extenders</b> that are compatible (<b>IKS01A1/IKS01A2/IKS01A3</b>), are used.</p>
<h2><a class="anchor" id="autotoc_md34"></a>
<a href="https://www.st.com/en/development-tools/unicleo-gui.html">&lt;span id="_Toc119493241" class="anchor"&gt;<b>Unicleo-GUI</b></a></h2>
<p><b>Unicleo-GUI</b>\[6\] is a graphical user interface (GUI) for the X-CUBE-MEMS1 and X-CUBE-MEMS-XT1 software expansions and STM32 Nucleo expansion boards (X-NUCLEO-IKS01A1, X-NUCLEO-IKS01A2, X-NUCLEO-IKS01A3 and X-NUCLEO-IKS02A1). The main objective of this application is to demonstrate the functionality of ST sensors and algorithms.</p>
<p>Unicleo-GUI is able to cooperate with firmware created by AlgoBuilder application and display data coming from the running firmware.</p>
<p>The application is also able to establish Bluetooth connection with BLE connectivity-equipped devices such as SensorTile (STEVAL- STLKT01V1), BlueCoin (STEVAL-BCNKT01V1), and STM32 Nucleo with X-NUCLEO-IDB05A1 expansion board, BlueTile (STEVAL-BCN002V1B) or WESU1 (STEVAL-WESU1) and read data from various device characteristics. The supported firmware for these devices can be found at FP-SNS-ALLMEMS1, FP-SNS-ALLMEMS2, FP-SNS-MOTENV1, FP-SNS-MOTENVWB1, STSW- BLUETILE-DK and STSW-WESU1.</p>
<h2><a class="anchor" id="autotoc_md35"></a>
<a href="https://www.st.com/en/development-tools/unico-gui.html">&lt;span id="_Toc119493242" class="anchor"&gt;<b>Unico-GUI</b></a></h2>
<p><b>Unico-GUI</b>\[7\] is a comprehensive software package for the evaluation boards of all MEMS sensors available in ST’s product portfolio (accelerometers, gyroscopes, magnetometers and environmental sensors).</p>
<p>The software is a cross-platform graphical user interface interacting with STEVAL-MKI109V3 (Professional MEMS tool) which is the motherboard compatible with all ST MEMS adapter boards. It is also possible to run UNICO offline (without the motherboard) for generating configurations of advanced features like the Machine Learning Core, Finite State Machine, and pedometer.</p>
<p>The platform allows quick and easy setup of the sensors, as well as the complete configuration of all the registers and advanced features (such as the Machine Learning Core, Finite State Machine, pedometer, etc.) embedded in the digital output devices. The software visualizes the output of the sensors in both graphical and numeric format, and allows the user to save or generally manage data coming from the device.</p>
<p>Examples of tools which support the advanced features are the following: FIFO tool that allows the user to buffer data with a high level of flexibility and burst the significant data out when needed; Finite State Machine tool that allows the user to configure the state machines, test their functionality and validate the program; Machine Learning Core tool that allows the user to configure a machine learning core starting from the management of data patterns and labeling to setting and generating the configuration file to run the algorithm; FFT tool that allows visualizing the Fast Fourier Transform of the output data; Pedometer tool that allows the user to configure and test the pedometer embedded in the device including an offline post-processing analysis;</p>
<h2><a class="anchor" id="autotoc_md36"></a>
<a href="https://www.cs.waikato.ac.nz/ml/index.html">&lt;span id="_Toc119493243" class="anchor"&gt;<b>Weka</b></a></h2>
<p><b>Weka</b>\[8\] contains a collection of visualization tools and algorithms for <a href="https://en.wikipedia.org/wiki/Data_analysis"><u>data anal</u>y<u>sis</u></a> and <a href="https://en.wikipedia.org/wiki/Predictive_modeling">p<u>redictive modeling</u></a>, together with graphical user interfaces for easy access to these functions.<a href="https://en.wikipedia.org/wiki/Weka_(machine_learning)#cite_note-%3A0-1">[</a><u>1]</u>. Advantages of Weka include:</p>
<ul>
<li>Portability, since it is fully implemented in the [<u>Java</u> p<u>rogramming language</u>](<a href="https://en.wikipedia.org/wiki/Java_programming_language">https://en.wikipedia.org/wiki/Java_programming_language</a>) and thus runs on almost any modern computing platform.</li>
<li>A comprehensive collection of data preprocessing and modeling techniques.</li>
<li>Ease of use due to its graphical user interfaces.</li>
</ul>
<p>Weka supports several standard <a href="https://en.wikipedia.org/wiki/Data_mining"><u>data minin</u>g</a> tasks, more specifically, data preprocessing, <a href="https://en.wikipedia.org/wiki/Data_clustering"><u>clusterin</u>g</a>, <a href="https://en.wikipedia.org/wiki/Statistical_classification"><u>classification</u></a>, <a href="https://en.wikipedia.org/wiki/Regression_analysis"><u>re</u>g<u>ression</u></a>, <a href="https://en.wikipedia.org/wiki/Data_visualization"><u>visualization</u></a>, and <a href="https://en.wikipedia.org/wiki/Feature_selection"><u>feature selection</u></a>.</p>
<p>Input to Weka is expected to be formatted according the Attribute-Relational File Format and with the filename bearing the **.arff** extension. All of Weka's techniques are predicated on the assumption that the data is available as one flat file or relation, where each data point is described by a fixed number of attributes (normally, numeric or nominal attributes, but some other attribute types are also supported). Weka provides access to <a href="https://en.wikipedia.org/wiki/SQL"><u>SQ</u></a>L <a href="https://en.wikipedia.org/wiki/Database">databases</a> using [<u>Java Database Connectivit</u>y](<a href="https://en.wikipedia.org/wiki/Java_Database_Connectivity">https://en.wikipedia.org/wiki/Java_Database_Connectivity</a>) and can process the result returned by a database query. Weka provides access to <a href="https://en.wikipedia.org/wiki/Deep_learning"><u>dee</u>p <u>learning</u></a> with <a href="https://en.wikipedia.org/wiki/Deeplearning4j"><u>Dee</u>p<u>learning4j</u></a>.<a href="https://en.wikipedia.org/wiki/Weka_(machine_learning)#cite_note-4">[</a><u>4]</u> It is not capable of multi-relational data mining, but there is separate software for converting a collection of linked database tables into a single table that is suitable for processing using Weka.<a href="https://en.wikipedia.org/wiki/Weka_(machine_learning)#cite_note-5">[</a><u>5]</u> Another important area that is currently not covered by the algorithms included in the Weka distribution is sequence modeling.</p>
<h1><a class="anchor" id="autotoc_md37"></a>
Implementation</h1>
<h2><a class="anchor" id="autotoc_md38"></a>
<b>STM32CubeIDE</b></h2>
<p><img src="images/unicleo1.png" alt="" style="width:5.94375in;height:3.225in" class="inline"/>First, the program needs to be flashed on the board. This needs to be done with <b>STM32CubeIDE</b>.</p>
<h2><a class="anchor" id="autotoc_md39"></a>
<b>Unicleo-GUI</b></h2>
<p>After the program was flashed to the board, the sensors are initialized and ready to be used.</p>
<p>This is the interface of <b>Unicleo</b>. If the board is connected via USB (ST Link) then the Serial Port</p>
<p><img src="images/unicleo1_2.png" alt="" style="width:5.84167in;height:3.22847in" class="inline"/>should be automatically selected, mine for example is COM5. **S*elect Connect***.</p>
<p>The sensors list will pop up and show all available sensors. Choose the <b>LSM6DSOX (DIL24)</b>.</p>
<p><b>Note</b> <b>that</b> there is also another sensor named LSM6DSO, that is the exact same sensor, but on the extender IKS01A3 and does not contain the Machine Learning Core.</p>
<blockquote class="doxtable">
<p>&zwj;<img src="images/unicleo2.png" alt="" style="width:5.82292in;height:3.23125in" class="inline"/> </p>
</blockquote>
<p>After <b>Apply</b> has been selected, the following window will pop up. It shows the sensors of the IKS01A3 and the MKI197V1 along with their locations on the board**.**</p>
<p><img src="images/unicleo3.png" alt="" style="width:5.84583in;height:3.27083in" class="inline"/>On the left the option for the visualization of the available sensors can be seen.</p>
<p>If <em><b>MLC</b></em> is chosen from the left, the user will be greeted by the following window. On the first block, named <em><b>Sensor Configuration</b></em>, a custom <em><b>.ucf</b></em> dataset can be loaded. Bellow that are some <em><b>Example Algorithms</b></em>, that, if chosen, they will be loaded and cording to the motion of the sensor, a different value will be shown on the <em><b>MLC Source Registers</b></em> bellow.</p>
<p><img src="images/unicleo4.png" alt="" style="width:2.50417in;height:3.47431in" class="inline"/>The values will be displayed on the blocks on the right of <em><b>MLC0_SRC</b></em>.</p>
<h2><a class="anchor" id="autotoc_md40"></a>
<b>Machine Learning Core Example</b></h2>
<p>For example, here are the specifics of the <em><b>Activity Recognition (Wrist)</b></em> algorithm.</p>
<p>According to the documentation of the algorithm:</p>
<ul>
<li><b>1 = Stationary/Other</b></li>
<li><b>4 = Walking/Fast Walking</b></li>
<li><b>8 = Jogging/Running</b></li>
</ul>
<p><img src="images/unicleo5.png" alt="" style="width:5.18073in;height:3.92823in" class="inline"/>*</p>
<p>Before an algorithm can be selected, <em><b>Start</b></em> must be selected on the main window, to activate the sensor. After that, the sensor will begin sending feedback.</p>
<p><img src="images/unicleo6.png" alt="Graphical user interface Description automatically generated" style="width:5.75784in;height:3.23257in" class="inline"/></p>
<p>Now, instead of using one of the example algorithms, a custom <em><b>.ucf</b></em> file will be created and used to show the configurations that need to be set. To do that, data must be logged into a dataset based on each action that one wants to add to the Decision Tree. The log will be created in Unicleo (in <em><b>.txt/ .csv</b></em> format) and then <em><b>Unico</b></em> will be used to create the <em><b>.ucf</b></em> file. Then the <em><b>.ucf</b></em> file will be loaded to <em><b>Weka</b></em> to create <em><b>Decision Tree</b></em> and after that it will be loaded back to <em><b>Unico</b></em>.</p>
<p><em>In order to log the data, the <b>Datalog</b> option needs to be chosen on the left of the main window. Next choose the sensors that you want to log into a file from both <b>Data</b> and <b>Datalog period source</b> ad set a file for said activity.</em></p>
<p><img src="images/unicleo7.png" alt="" style="width:3.86528in;height:2.61597in" class="inline"/>*Here, motions will be monitored for approximately 1 minute and saved in a dataset file <b>karate.csv</b>. <br  />
</p>
<p>The same steps will be followed for the dataset <em><b>boxing.csv .</b></em></p>
<p><img src="images/unico1.png" alt="" style="width:4.07778in;height:2.71875in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md41"></a>
<b>Unico-GUI</b></h2>
<p>Now <em><b>Unico</b></em> needs to be used in order to create a file that can be read by <em><b>Weka</b></em>.</p>
<p>Since Unico cannot be used with the shield <em><b>IKS01A3</b></em>, it will have to be used in offline mode. That means that it will not connect with the board, but the datasets will be able to be loaded in order to extract an <em><b>.arff</b></em> file.</p>
<p><img src="images/unico2.png" alt="" style="width:5.31389in;height:2.85417in" class="inline"/>Select in the <b>iNemo Inertial Modules</b> the <em><b>STEVAL-MKI197V1 (LSM6DSOX)</b></em> sensor and deselect the <em><b>Communication with the motherboard</b></em> option. Then click on <em><b>Select Device</b></em>.</p>
<p><img src="images/unico3.png" alt="" style="width:4.09514in;height:3.14583in" class="inline"/>After the main window shows up, select <em><b>MLC</b></em> on the left and the <em><b>Machine Learning Core</b></em> \[9\] window will open.</p>
<p>Now each one of the datasets will be loaded and set the <em><b>Class Label</b></em> as <em><b>boxing</b></em> for the <b>Boxing</b> Dataset and <b>Karate</b> for the Karate Dataset.</p>
<p><img src="images/unico4.png" alt="Graphical user interface, table Description automatically generated" style="width:6.02328in;height:3.56036in" class="inline"/></p>
<p><img src="images/unico5.png" alt="" style="width:5.86458in;height:3.42222in" class="inline"/>Then, the <em><b>Configuration</b></em> Tab must be selected. Here are the options that were given to the <em><b>Decision Tree.</b></em></p>
<p>The chosen options were all the <em><b>Signed</b></em> options <em><b>ACC_X, ACC_Y, ACC_Z, GY_X, GY_Z</b></em> for the <em><b>Mean**, <b>Variance</b>, <b>Energy</b> and <b>Peak</b> <b>to</b> **Peak</b></em> features.</p>
<p><img src="images/unico6.png" alt="" style="width:5.60417in;height:3.30139in" class="inline"/></p>
<p><img src="images/unico7.png" alt="" style="width:5.65145in;height:3.29564in" class="inline"/></p>
<p>Save the file as **.arff** and choose the desired output values of the <b>Decision Tree</b>.</p>
<ul>
<li><b>1</b> was set for <b>Karate</b> and <b>2</b> for <b>Boxing</b>.</li>
</ul>
<p><img src="images/unico8.png" alt="" style="width:6.49306in;height:3.85903in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md42"></a>
<b>Weka</b></h2>
<p><img src="images/weka.png" alt="" style="width:4.42153in;height:3.32986in" class="inline"/>Open <em><b>Weka</b></em> <em><b>Explorer</b></em> and load the <b>sports.arff</b> file that was created above:</p>
<p>Select the <em><b>Classify Tab</b></em> and then <em><b>Choose</b></em> on the <em><b>Classifier** **Block</b></em> and select the <em><b>J48</b></em> in the tree section. The <em><b>Cross-Validation Folds</b></em> option was set on 10, as default, since it gives an approximate 98% result.</p>
<p><img src="images/weka2.png" alt="" style="width:5.64306in;height:4.24375in" class="inline"/></p>
<p><img src="images/weka3.png" alt="" style="width:6.1437in;height:3.36458in" class="inline"/>The <em><b>Decision Tree</b></em> has been generated, but in order to load it into <em><b>Unico</b></em> to create the <em><b>.ucf</b></em> file, the selected text, as seen in the image below (<em><b>The tree itself</b></em>), needs to be copied and pasted into a <em><b>.txt</b></em> file.</p>
<p><img src="images/weka4.png" alt="" style="width:3.85694in;height:3.1875in" class="inline"/></p>
<p>And to see the <em><b>Decision Tree</b></em>, right click on the <em><b>Result List</b></em> and select <em><b>Visualize Tree</b></em>.</p>
<p><img src="images/weka5.png" alt="" style="width:5.64236in;height:4.23958in" class="inline"/></p>
<p><img src="images/weka6.png" alt="" style="width:6.02083in;height:3.51042in" class="inline"/>Now the **.txt** file can be loaded into the <em><b>Unico</b></em> window that was left intact a while ago.</p>
<p>And save the file as <em><b>sports.ucf</b></em>.</p>
<p><img src="images/unico_mlc.png" alt="" style="width:2.92708in;height:4.09653in" class="inline"/> Now the <b>sports.ucf</b> file can be loaded into <b>Unicleo</b> in the <b>MLC</b> (Machine Learning Core) option.</p>
<p><img src="images/final1.png" alt="" style="width:2.48819in;height:3.43472in" class="inline"/></p>
<p>Here the changes can be seen as the value changes to <b>0x01</b> in <em><b>MLC0_SRC</b></em> when the board mimics the action for <b>Karate</b> .</p>
<p><img src="images/final2.png" alt="" style="width:2.6375in;height:3.72083in" class="inline"/></p>
<p>And here <em><b>MLC0_SRC</b></em> changes to <em><b>2</b></em> when the board mimics the action for <b>Boxing</b>.</p>
<p><img src="images/final3.png" alt="" style="width:2.6375in;height:3.72083in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md43"></a>
<b>Video Demonstration</b></h2>
<p><a href="https://www.youtube.com/watch?v=m6ylfVGBezo">Here is a video demonstration of the</a> <em><b>LSM6DSOX</b></em> sensor changing value from <em>1</em> to <em>2</em> when it recognizes the different actions.</p>
<blockquote class="doxtable">
<p>&zwj;<a href="https://www.youtube.com/watch?v=m6ylfVGBezo">**<u>Machine Learning Core LSM6DSOX Demonstration</u> \|\| <u>ISCA Lab</u>**</a> \[10\] </p>
</blockquote>
<p><img src="images/6_6.JPG" alt="" style="width:5.83472in;height:3.45347in" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md44"></a>
<b>Falling Detection Algorithm</b></h1>
<blockquote class="doxtable">
<p>&zwj;This example is made for the use-case of detecting the Fall of the device from <b>Low</b> or <b>High altitude</b>. It demonstrates the change on the registers of the Machine Learning Core of Unicleo when the board is free-falling from both a low and high altitude.</p>
<p>In order to create the datasets for both falls, a scenario was created for logging the Data for each case. </p>
</blockquote>
<h2><a class="anchor" id="autotoc_md45"></a>
<b>Creation of Falling Detection Datasets</b></h2>
<blockquote class="doxtable">
<p>&zwj;<b>Low and High Altitude Fall</b></p>
<p>For both the <b>Low</b> and <b>High</b> altitude fall, 2 datasets were created with the board mimicking each fall, in a safe environment, from a height of approximately 90 centimeters for the <b>Low</b> fall and approximately 2.5 meters for the <b>High</b> fall.</p>
<p>For this scenario, the mechanism that was created consisted of a small rubber rope attached to a thin rope, used to avoid damage from the force of the velocity, whereas the rope was used to simulate the fall by hand.</p>
<p>Logs were taken from each scenario and then loaded into the same Decision Tree in order to have a single configuration for detecting both Falls at the same time.</p>
<p>In the video shown below, the changes of the registers may not be exact at times (changing from Low to High when falling) and that is because of the bounce of the board due to the rubber that was used to simulate a safe Fall.</p>
<p>Since the algorithm detects the data mostly from the accelerometer, when falling it may detect a greater value, but when the rubber bounces back it simulates the velocity of a Low altitude fall ,and so, it detects it as such. In a real-world scenario, where the board is not in a safe environment, the fall would be one-way and the board wouldn't bounce, since it would most likely not be attached to anything, except maybe a cable.</p>
<p>In that scenario, the algorithm would detect only one Fall, and the prediction would be more precise.</p>
<p>Although, as most uses of a Machine Learning algorithm, many datasets need to be logged and merged for either the <b>IDLE</b> state of the board or the <b>Falling Detection</b>. This will lead to a more precise algorithm with a variety of predictions and broader spectrum of detections for different scenarios, angles and falls. </p>
</blockquote>
<h2><a class="anchor" id="autotoc_md46"></a>
<b>Project Equipment</b></h2>
<blockquote class="doxtable">
<p>&zwj;**<u> <br  />
 </u>**<img src="images/front1_edited.png" alt="" style="width:5.35631in;height:3.65903in" class="inline"/>** <br  />
 **<img src="images/base_edited.png" alt="" style="width:5.35631in;height:3.65903in" class="inline"/>** <br  />
 </p>
</blockquote>
<blockquote class="doxtable">
<p>&zwj;** </p>
</blockquote>
<h2><a class="anchor" id="autotoc_md47"></a>
<b>Video Demonstration</b></h2>
<p>This video demonstrates the different fall detections that the Machine Learning Core predicts from the output of the <b>Accelerometer</b> and <b>Gyroscope</b> of the <b>LSM6DSOX</b> Sensor.</p>
<p>MLC Source Register <em><b>0x70 MLC_SRC</b></em> values in Unicleo:</p>
<ul>
<li><b>0x01 -&gt;</b> Value for the board being <b>IDLE</b></li>
<li><b>0x04 -&gt;</b> Value for the board falling from a <b>Low Altitude</b></li>
<li><b>0x08 -&gt;</b> Value for the board falling from a **High Altitude <br  />
</li>
</ul>
<p>[<b>Falling Detection with Machine Learning Core STM MEMS Sensor LSM6DSOX || ISCA Lab</b> [11]](\l)</p>
<p>[<img src="images/2022-09-08_13-39.png" alt="" style="width:5.69446in;height:3.07083in" class="inline"/>](\l)</p>
<h2><a class="anchor" id="autotoc_md48"></a>
<b>Possible Real-World Use Scenarios</b></h2>
<p>A possible scenario of such a use case, such as the one shown above, would be the use of a device with capabilities of <b>Bluetooth</b> connectivity.</p>
<p>Such a scenario would prove to be a more efficient solution to provide wireless data of a device in a monitoring database or simple real-time feedback to a computer.</p>
<p>The device that was available for this demo did not have <b>Bluetooth</b> connectivity and so such a scenario was not recorded, but would bare the same results.</p>
<p>For example, both <b>Unico</b> and <b>Unicleo</b> have an option to enable <b>Bluetooth</b> via their GUI interface. After that, the scenario of logging the data in a remote computer/database could be explored, in the future, for providing information of devices in case of their required position is compromised.</p>
<h1><a class="anchor" id="autotoc_md49"></a>
<b>Falling Detection Algorithm With NUCLEO-WL55JCx and SHUBv3</b></h1>
<p>This section covers the demonstration of a real use-case scenario for the Falling Detection Algorithm that was described previously. The microcontroller that was used is the <b>NUCLEO-WL55JCx</b>, in addition with the <b>Sensor Hub v3</b> (<b>SHUBv3</b>) and on top of that is connected the <b>MKI197v1</b> adapter board that uses the <b>LSM6DSOX</b> sensor to detect any movement of the board and provide output based on the dataset that was given to it.</p>
<p>In contrary with the previous demonstration, this board is not in the supported devices of the <b>X-NUCLEO-MEMS1</b> package, and thus a custom firmware needed to be developed, to enable communication with the <b>SHUBv3</b> and the <b>MKI197v1</b> adapter board.</p>
<p>To enable the <b>Machine Learning Core</b> in this project, the LSM6DSOX had to be included in the project manually, along with the <b>MLC</b> option, provided by ST in their <a href="https://github.com/STMicroelectronics/STMems_Standard_C_drivers/blob/master/lsm6dsox_STdC/examples/lsm6dsox_mlc.c">GitHub</a> repository.</p>
<p>In order to be able to monitor and log the data for the decision tree, a different firmware was developed, that enabled the <b>Unicleo-GUI</b> application and allowed the DataLog of the simulation data.</p>
<p>The steps that were followed were exactly the same as shown in the sections 4.1 - 4.5, with the exception that the .ucf file was converted into a header (.h) file and was used in the firmware. That way the output of the <b>MLC</b> option was based registers that were given when the Decision Tree was created.</p>
<h2><a class="anchor" id="autotoc_md50"></a>
<b>Equipment</b></h2>
<ul>
<li>WL55JCx (x = 1 or 2)</li>
</ul>
<p><img src="images/wl55jc.svg" alt="" style="pointer-events: none; width:2.64582in;height:4.70369in" class="inline"/></p>
<ul>
<li>SHUBv3</li>
</ul>
<p><img src="images/hub.svg" alt="A picture containing text, circuit, electronics Description automatically generated" style="pointer-events: none; width:4.18512in;height:3.13697in" class="inline"/></p>
<ul>
<li>WL55JCx + SensorHubV3 + MKI197v1</li>
</ul>
<p><img src="images/hardware.svg" alt="A picture containing text, indoor, blue Description automatically generated" style="pointer-events: none; width:4.51875in;height:4.27272in" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md51"></a>
<b>Decision Tree Generation</b></h2>
<p>The decision tree was generated based on the datasets that were logged for this project, which include:</p>
<ol type="1">
<li><b>Idle Position</b></li>
<li><b>Low Fall Detection</b></li>
<li><b>High Fall Detection</b></li>
</ol>
<p>The tree was generated with WEKA, using <b>10-Fold Cross-Validation</b> and the <b>J48</b> algorithm.</p>
<h3><a class="anchor" id="autotoc_md52"></a>
<b>K-fold Cross-Validation</b></h3>
<p>Cross validation is one of the techniques used to test the effectiveness of machine learning models and avoid overfitting. It is a re-sampling procedure used to evaluate a model, and with the option of 5 or 10 folds (e.g., 10-fold Cross-Validation), the procedure can be executed without using excessive computation sources in order to train the model.</p>
<p>With K-fold Cross-Validation we divide the data set into k-subsets and the procedure is repeated k-times. A training set is created, which consists of k-1 subsets and a testing set consisting of the remaining subsets.</p>
<p>For example, in 10-fold Cross-Validation, the procedure would perform a total number of ten times, reserving 9/10 parts for training and the remaining 1/10<sup>th</sup> for testing, each time reserving a different tenth for testing.</p>
<h3><a class="anchor" id="autotoc_md53"></a>
<b>J48 Algorithm (also known as C4.5)</b></h3>
<p>The C4.5 algorithm for building decision trees is implemented in Weka as a classifier <br  />
 called J48. The decision trees from this algorithm are generated using the concept of <b>information entropy</b> and can be used for <b>classification</b>.</p>
<ul>
<li><b>Information entropy</b> is a measure of how much information there is in some specific data. It isn't the length of the data, but the actual amount of information it contains.</li>
</ul>
<p>For example, <b>one text file could contain “Apples are red.” and another text file could contain “Apples are red.</b> <b>Apples are red.</b></p>
<ul>
<li><b>Classification</b> refers to a supervised learning concept which basically categorizes a set of data into classes.</li>
</ul>
<p>Classifiers, like filters, are organized in a hierarchy: J48 has the full name <br  />
 weka.classifiers.trees.J48. The classifier is shown in the text box next to the Choose <br  />
 button: It reads J48 –C 0.25 –M 2. This text gives the default parameter settings for this <br  />
 classifier. <br  />
 C4.5 has several parameters, by the default visualization (when you invoke the <br  />
 classifier) only shows –c ie. Confidence value (default 25%): lower values incur heavier <br  />
 pruning and -­‐M ie. Minimum number of instances in the two most popular branches <br  />
 (default 2). The full set of J48 parameter settings are explained here: <br  />
 <a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/trees/J48.html%20">http://weka.sourceforge.net/doc.dev/weka/classifiers/trees/J48.html</a> </p>
<h2><a class="anchor" id="autotoc_md54"></a>
<b>Performance</b></h2>
<p>For the configuration that was given for this decision tree, the following test summary was given by the WEKA toolchain:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone"><b>Correctly Classified Instances</b>   </th><th class="markdownTableHeadNone">51   </th><th class="markdownTableHeadNone">80.9524 %    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Incorrectly Classified Instances</b>   </td><td class="markdownTableBodyNone">12   </td><td class="markdownTableBodyNone">19.0476 %    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Kappa statistic</b>   </td><td class="markdownTableBodyNone">0.7056   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Mean absolute error</b>   </td><td class="markdownTableBodyNone">0.1263   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Root mean squared error</b>   </td><td class="markdownTableBodyNone">0.3398   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Relative absolute error</b>   </td><td class="markdownTableBodyNone">29.1923 %   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone"><b>Root relative squared error</b>   </td><td class="markdownTableBodyNone">73.0292 %   </td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone"><b>Total Number of Instances</b>   </td><td class="markdownTableBodyNone">63   </td><td class="markdownTableBodyNone"></td></tr>
</table>
<h2><a class="anchor" id="autotoc_md55"></a>
<b>Video Demonstration</b></h2>
<p>The video demonstrates the values of the registers that are generated by the Machine Learning Core based on the header file that was included in the firmware.</p>
<p><b>[Falling Detection with Machine Learning Core Sensor LSM6DSOX - WL55JCx + SensorHub || ISCA Lab](<a href="https://www.youtube.com/watch?v=GsexEODn7TA">https://www.youtube.com/watch?v=GsexEODn7TA</a>) \[12\]</b></p>
<p><img src="images/hardware.svg" alt="A picture containing text, indoor, blue Description automatically generated" style="pointer-events: none; width:4.51875in;height:4.27272in" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md56"></a>
Power Measurement</h3>
<p><img src="images/osciliometer.jpg" alt="" style="width:4.51875in;height:4.27272in" class="inline"/> <img src="images/all_together.svg" alt="" style="pointer-events: none; width:4.51875in;height:4.27272in" class="inline"/> <img src="images/2022-11-13_10-19.png" alt="" style="width:4.51875in;height:4.27272in" class="inline"/> <img src="images/activity_MLC.png" alt="" style="width:4.51875in;height:4.27272in" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md57"></a>
<b>References</b></h1>
<ol type="1">
<li><a href="https://teicrete-my.sharepoint.com/personal/tp4591_edu_hmu_gr/Documents/B-L072Z-LRWAN1"><b>B-L072Z-LRWAN1</b></a>, <a href="https://www.st.com/en/evaluation-tools/b-l072z-lrwan1.html">https://www.st.com/en/evaluation-tools/b-l072z-lrwan1.html</a></li>
<li>**X-NUCLEO-IKS01A3**, <a href="https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html">https://www.st.com/en/ecosystems/x-nucleo-iks01a3.html</a></li>
<li>**STEVAL-MKI197V1**, <a href="https://www.st.com/en/evaluation-tools/steval-mki197v1.html">https://www.st.com/en/evaluation-tools/steval-mki197v1.html</a></li>
<li>**I3C**, <a href="https://en.wikipedia.org/wiki/I3C_(bus)">https://en.wikipedia.org/wiki/I3C_(bus)</a></li>
<li>**X-CUBE-MEMS1 Firmware Package**,</li>
</ol>
<p><a href="https://github.com/STMicroelectronics/X-CUBE-MEMS1">https://github.com/STMicroelectronics/X-CUBE-MEMS1</a></p>
<ol type="1">
<li>**Unicleo-GUI**, <a href="https://www.st.com/en/development-tools/unicleo-gui.html">https://www.st.com/en/development-tools/unicleo-gui.html</a></li>
<li>**Unico-GUI**, <a href="https://www.st.com/en/development-tools/unico-gui.html">https://www.st.com/en/development-tools/unico-gui.html</a></li>
<li>**Weka**, <a href="https://www.cs.waikato.ac.nz/ml/index.html">https://www.cs.waikato.ac.nz/ml/index.html</a></li>
<li>**Unico’s Machine Learning Core User Guide**,</li>
</ol>
<p><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiD8Jjfh5T6AhV-hf0HHevHC7AQFnoECB8QAQ&url=https%3A%2F%2Fwww.st.com%2Fresource%2Fen%2Fuser_manual%2Fcd00297387-unico-gui-stmicroelectronics.pdf&usg=AOvVaw3QMf286kZJigIy6RPmtIM2">https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwiD8Jjfh5T6AhV-hf0HHevHC7AQFnoECB8QAQ&amp;url=https%3A%2F%2Fwww.st.com%2Fresource%2Fen%2Fuser_manual%2Fcd00297387-unico-gui-stmicroelectronics.pdf&amp;usg=AOvVaw3QMf286kZJigIy6RPmtIM2</a></p>
<ol type="1">
<li>**Machine Learning Core LSM6DSOX Demonstration \|\| ISCA Lab**, <a href="https://www.youtube.com/watch?v=m6ylfVGBezo">https://www.youtube.com/watch?v=m6ylfVGBezo</a></li>
<li>**Falling Detection with Machine Learning Core STM MEMS Sensor LSM6DSOX \|\| ISCA Lab**, <a href="https://www.youtube.com/watch?v=tSlJXf_sjQc&feature=youtu.be">https://www.youtube.com/watch?v=tSlJXf_sjQc&amp;feature=youtu.be</a></li>
<li><b>Falling Detection with Machine Learning Core Sensor LSM6DSOX - WL55JCx + SensorHub || ISCA Lab,</b> <a href="https://www.youtube.com/watch?v=GsexEODn7TA">https://www.youtube.com/watch?v=GsexEODn7TA</a> </li>
</ol>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0 </li>
  </ul>
</div>
</body>
</html>
